{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing my models against Iris Dataset and comapre With Sklearn models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from evaluator.model_evaluator import ModelEvaluator\n",
    "\n",
    "from models.knn import Conformal,NearestNeighbours\n",
    "from models.decision_tree import DecisionTree\n",
    "from models.random_forest import RandomForest\n",
    "from models.elm import ELM as custom_ELM\n",
    "from models.logistic_regression import LogisticRegression\n",
    "from models.logistic_regression import LogisticRegression\n",
    "from models.weighted_lr import WeightedLogisticRegression\n",
    "\n",
    "from evaluator.model_evaluator import ModelEvaluator\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Splitting and loading iris dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Iris dataset\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SKLEARN KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for sklearn KNN: {'accuracy': 1.0, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'f2_score': 1.0}\n"
     ]
    }
   ],
   "source": [
    "knn_classifier = KNeighborsClassifier(n_neighbors=1)\n",
    "knn_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = knn_classifier.predict(X_test)\n",
    "# Evaluate the model\n",
    "metrics = ModelEvaluator.calculate_metrics(y_test, y_pred)\n",
    "print(f\"Metrics for sklearn KNN: {metrics}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MY KNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for sklearn KNN: {'accuracy': 1.0, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'f2_score': 1.0}\n"
     ]
    }
   ],
   "source": [
    "knn_model = NearestNeighbours(neighbours=1)\n",
    "knn_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = knn_classifier.predict(X_test)\n",
    "# Evaluate the model\n",
    "metrics = ModelEvaluator.calculate_metrics(y_test, y_pred)\n",
    "print(f\"Metrics for sklearn KNN: {metrics}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Validation Summary\n",
    "\n",
    "The custom KNN model was validated against scikit-learn's KNN implementation on the Iris dataset. Both models produced identical metrics:\n",
    "\n",
    "- **Accuracy**: 1.0  \n",
    "- **Precision**: 1.0  \n",
    "- **Recall**: 1.0  \n",
    "- **F1-Score**: 1.0  \n",
    "- **F2-Score**: 1.0  \n",
    "\n",
    "This confirms the correctness of my KNN model implementation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sklearn DT model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for sklearn DT: {'accuracy': 1.0, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'f2_score': 1.0}\n",
      "Metrics for sklearn DT: {'accuracy': 0.9777777777777777, 'precision': 0.9285714285714286, 'recall': 1.0, 'f1_score': 0.962962962962963, 'f2_score': 0.9848484848484849}\n"
     ]
    }
   ],
   "source": [
    "# Scikit-learn Decision Tree\n",
    "sklearn_dt = DecisionTreeClassifier(criterion=\"gini\",max_depth=10,min_samples_split=2,random_state=42)\n",
    "sklearn_dt.fit(X_train, y_train)\n",
    "y_dt_pred_sklearn = sklearn_dt.predict(X_test)\n",
    "metrics = ModelEvaluator.calculate_metrics(y_test, y_dt_pred_sklearn)\n",
    "print(f\"Metrics for sklearn DT: {metrics}\")\n",
    "\n",
    "# Scikit-learn Decision Tree\n",
    "sklearn_dt = DecisionTreeClassifier(criterion=\"entropy\",max_depth=10,min_samples_split=2,random_state=42)\n",
    "sklearn_dt.fit(X_train, y_train)\n",
    "y_dt_pred_sklearn = sklearn_dt.predict(X_test)\n",
    "metrics = ModelEvaluator.calculate_metrics(y_test, y_dt_pred_sklearn)\n",
    "print(f\"Metrics for sklearn DT: {metrics}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### My Implmentation of Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for custom Decision Tree: {'accuracy': 0.9555555555555556, 'precision': 1.0, 'recall': 0.8461538461538461, 'f1_score': 0.9166666666666666, 'f2_score': 0.8730158730158731}\n",
      "Metrics for custom Decision Tree: {'accuracy': 0.9555555555555556, 'precision': 1.0, 'recall': 0.8461538461538461, 'f1_score': 0.9166666666666666, 'f2_score': 0.8730158730158731}\n"
     ]
    }
   ],
   "source": [
    "# Custom Decision Tree\n",
    "custom_dt = DecisionTree(uniformity_measure=\"gini\", max_depth=None, min_samples_split=2)\n",
    "custom_dt.fit(X_train, y_train)\n",
    "y_dt_pred_custom = custom_dt.predict(X_test)\n",
    "metrics_custom = ModelEvaluator.calculate_metrics(y_test, y_dt_pred_custom)\n",
    "print(f\"Metrics for custom Decision Tree: {metrics_custom}\")\n",
    "\n",
    "# Custom Decision Tree\n",
    "custom_dt = DecisionTree(uniformity_measure=\"entropy\", max_depth=None, min_samples_split=2)\n",
    "custom_dt.fit(X_train, y_train)\n",
    "y_dt_pred_custom = custom_dt.predict(X_test)\n",
    "metrics_custom = ModelEvaluator.calculate_metrics(y_test, y_dt_pred_custom)\n",
    "print(f\"Metrics for custom Decision Tree: {metrics_custom}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation:**  \n",
    "My custom decision tree implementation still produces valid predictions. However scikit-learnâ€™s DecisionTreeClassifier achieves higher training accuracy due to optimised threshold selection, and other internal refinements. Sklearn DT model was rigorously tested and improved and plan to investigate further where differences lie.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### My Random Forest vs Sklearn's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for sklearn Random Forest: {'accuracy': 1.0, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'f2_score': 1.0}\n",
      "Metrics for custom Random Forest: {'accuracy': 1.0, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'f2_score': 1.0}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Sk-learn Random Forest\n",
    "\n",
    "sklearn_rf = RandomForestClassifier(n_estimators=100, max_depth=10, random_state=42)\n",
    "sklearn_rf.fit(X_train, y_train)\n",
    "y_rf_pred_sklearn = sklearn_rf.predict(X_test)\n",
    "metrics_sklearn_rf = ModelEvaluator.calculate_metrics(y_test, y_rf_pred_sklearn)\n",
    "print(f\"Metrics for sklearn Random Forest: {metrics_sklearn_rf}\")\n",
    "\n",
    "# Custom Random Forest\n",
    "custom_rf = RandomForest(n_estimators=100, max_depth=10 )\n",
    "custom_rf.fit(X_train, y_train)\n",
    "y_rf_pred_custom = custom_rf.predict(X_test)\n",
    "metrics_custom_rf = ModelEvaluator.calculate_metrics(y_test, y_rf_pred_custom)\n",
    "print(f\"Metrics for custom Random Forest: {metrics_custom_rf}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "##### Both the scikit-learn and custom Random Forest implementations achieved identical metrics on the Iris dataset:\n",
    "\n",
    "- **Accuracy**: 1.0  \n",
    "- **Precision**: 1.0  \n",
    "- **Recall**: 1.0  \n",
    "- **F1-Score**: 1.0  \n",
    "- **F2-Score**: 1.0  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Breast Cancer Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "data = load_breast_cancer()\n",
    "X, y = data.data, data.target \n",
    "\n",
    "# Scaling\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression: SKlearn vs Custom Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for sklearn Logistic Regression: {'accuracy': 0.9736842105263158, 'precision': 0.9722222222222222, 'recall': 0.9859154929577465, 'f1_score': 0.979020979020979, 'f2_score': 0.9831460674157303}\n",
      "Metrics for custom Logistic Regression: {'accuracy': 0.9824561403508771, 'precision': 0.9859154929577465, 'recall': 0.9859154929577465, 'f1_score': 0.9859154929577465, 'f2_score': 0.9859154929577466}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression as SklearnLogisticRegression\n",
    "\n",
    "# Sklearn Logistic Regression\n",
    "sklearn_lr = SklearnLogisticRegression(max_iter=1000, random_state=42)\n",
    "sklearn_lr.fit(X_train, y_train)\n",
    "y_lr_pred_sklearn = sklearn_lr.predict(X_test)\n",
    "metrics_sklearn_lr = ModelEvaluator.calculate_metrics(y_test, y_lr_pred_sklearn)\n",
    "print(f\"Metrics for sklearn Logistic Regression: {metrics_sklearn_lr}\")\n",
    "\n",
    "# Custom Logistic Regression\n",
    "custom_lr = LogisticRegression(eta=0.01, epochs=500, lambda_reg=0.0, threshold=0.5)\n",
    "custom_lr.fit(X_train, y_train)\n",
    "y_lr_pred_custom = custom_lr.predict(X_test)\n",
    "metrics_custom_lr = ModelEvaluator.calculate_metrics(y_test, y_lr_pred_custom)\n",
    "print(f\"Metrics for custom Logistic Regression: {metrics_custom_lr}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Custom vs Sklearn Logistic Regression\n",
    "\n",
    "**Metrics Comparison:**\n",
    "\n",
    "- **Accuracy**: Sklearn LR - 0.9737, Custom LR - 0.9825  \n",
    "- **Precision**: Sklearn LR - 0.9722, Custom LR - 0.9859  \n",
    "- **Recall**: Sklearn LR - 0.9859, Custom LR - 0.9859  \n",
    "- **F1-Score**: Sklearn LR - 0.9790, Custom LR - 0.9859  \n",
    "- **F2-Score**: Sklearn LR - 0.9831, Custom LR - 0.9859  \n",
    "\n",
    "**Observation:**  \n",
    "My implementation slightly outperforms scikit-learn's Logistic Regression in accuracy and precision while maintaining identical recall. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weighted Logistic Regression: SKlearn vs Custom Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sklearn Weighted Logistic Regression: {'accuracy': 0.9824561403508771, 'precision': 0.9726027397260274, 'recall': 1.0, 'f1_score': 0.9861111111111112, 'f2_score': 0.9943977591036416}\n",
      "custom Weighted Logistic Regression: {'accuracy': 0.9824561403508771, 'precision': 0.9726027397260274, 'recall': 1.0, 'f1_score': 0.9861111111111112, 'f2_score': 0.9943977591036416}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression as SklearnWeightedLogisticRegression\n",
    "\n",
    "# Sklearn Weighted Logistic Regression\n",
    "cw = {0: 1.0, 1: 2.0} \n",
    "\n",
    "sklearn_wlr = SklearnWeightedLogisticRegression(max_iter=1000, random_state=42, class_weight=cw)\n",
    "sklearn_wlr.fit(X_train, y_train)\n",
    "y_wlr_pred_sklearn = sklearn_wlr.predict(X_test)\n",
    "metrics_sklearn_wlr = ModelEvaluator.calculate_metrics(y_test, y_wlr_pred_sklearn)\n",
    "print(f\"sklearn Weighted Logistic Regression: {metrics_sklearn_wlr}\")\n",
    "\n",
    "# Custom Weighted Logistic Regression\n",
    "custom_wlr = WeightedLogisticRegression(eta=0.01, epochs=500, lambda_reg=0.0, threshold=0.5, class_weights=cw)\n",
    "custom_wlr.fit(X_train, y_train)\n",
    "y_wlr_pred_custom = custom_wlr.predict(X_test)\n",
    "metrics_custom_wlr = ModelEvaluator.calculate_metrics(y_test, y_wlr_pred_custom)\n",
    "print(f\"custom Weighted Logistic Regression: {metrics_custom_wlr}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Metrics Comparison:\n",
    "\n",
    "- **Accuracy**: Sklearn Weighted LR - 0.9825, Custom Weighted LR - 0.9825  \n",
    "- **Precision**: Sklearn Weighted LR - 0.9726, Custom Weighted LR - 0.9726  \n",
    "- **Recall**: Sklearn Weighted LR - 1.0, Custom Weighted LR - 1.0\n",
    "- **F1-Score**: Sklearn Weighted LR - 0.9861, Custom Weighted LR - 0.9861  \n",
    "- **F2-Score**: Sklearn Weighted LR - 0.9944, Custom Weighted LR - 0.9944  \n",
    "\n",
    "Observation:  my implementation and sklearn implementations of Weighted Logistic Regression achieved identical metrics on the Breast Cancer dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extreme Learning Machine: hpelm library vs Custom Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hpelm ELM: {'accuracy': np.float64(0.9649122807017544), 'precision': np.float64(0.971830985915493), 'recall': np.float64(0.971830985915493), 'f1_score': np.float64(0.971830985915493), 'f2_score': np.float64(0.9718309859154931)}\n",
      "Custom ELM: {'accuracy': np.float64(0.9649122807017544), 'precision': np.float64(0.958904109589041), 'recall': np.float64(0.9859154929577465), 'f1_score': np.float64(0.9722222222222222), 'f2_score': np.float64(0.9803921568627452)}\n"
     ]
    }
   ],
   "source": [
    "from hpelm import ELM as HPELM\n",
    "\n",
    "# hpelm ELM\n",
    "hpelm_elm = HPELM(X_train.shape[1], 2, classification=\"c\", precision='single')\n",
    "y_train_hpelm = np.eye(2)[y_train]  # one-hot encoding for hpelm, my version not needed\n",
    "hpelm_elm.add_neurons(100, \"sigm\")  # sigmoid activation\n",
    "hpelm_elm.train(X_train, y_train_hpelm, \"c\")\n",
    "y_hpelm_pred = hpelm_elm.predict(X_test).argmax(axis=1)\n",
    "\n",
    "metrics_hpelm_elm = ModelEvaluator.calculate_metrics(y_test, y_hpelm_pred)\n",
    "print(f\"hpelm ELM: {metrics_hpelm_elm}\")\n",
    "\n",
    "cust_elm = custom_ELM(hidden_nodes=100, activation='sigmoid', random_state=None)\n",
    "cust_elm.fit(X_train, y_train)\n",
    "cust_elm_pred = cust_elm.predict(X_test)\n",
    "metrics_cust_elm = ModelEvaluator.calculate_metrics(y_test, cust_elm_pred)\n",
    "print(f\"Custom ELM: {metrics_cust_elm}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Metrics Comparison: hpelm vs Custom ELM\n",
    "\n",
    "**Observation:**  \n",
    "Both hpelm and my custom ELM implementation have matching metrics with very slight differences. My custom ELM achieves slightly higher recall and F2-Score, while hpelm has a marginally better precision. I can confidently say my model implementations are valid."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
